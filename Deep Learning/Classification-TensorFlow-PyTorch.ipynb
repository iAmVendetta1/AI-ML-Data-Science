{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498f9201-5ea7-4934-a80f-7391c5e96daa",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "92f84814-9262-4793-a30e-669fb3dc58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from windrose import WindroseAxes\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import sys\n",
    "import keras_tuner as kt\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429de6f-c645-44fa-8ff5-2e0175208457",
   "metadata": {},
   "source": [
    "# Load Dataset into Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5a6525bd-6678-43f2-978a-c53703cd8586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  TEMP  \\\n",
       "0   1  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0  -0.7   \n",
       "1   2  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0  -1.1   \n",
       "2   3  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0  -1.1   \n",
       "3   4  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0  -1.4   \n",
       "4   5  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0  -2.0   \n",
       "\n",
       "     PRES  DEWP  RAIN   wd  WSPM       station  \n",
       "0  1023.0 -18.8   0.0  NNW   4.4  Aotizhongxin  \n",
       "1  1023.2 -18.2   0.0    N   4.7  Aotizhongxin  \n",
       "2  1023.5 -18.2   0.0  NNW   5.6  Aotizhongxin  \n",
       "3  1024.5 -19.4   0.0   NW   3.1  Aotizhongxin  \n",
       "4  1025.2 -19.5   0.0    N   2.0  Aotizhongxin  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/kelby/Desktop/Master's in AI/5-Deep Learning (DSCI-619)/3 - Classification - TF PT/PRSA_Data/PRSA_Data1.csv\")\n",
    "\n",
    "# Display the merged dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3541f3-509a-450f-adea-db206cf334ff",
   "metadata": {},
   "source": [
    "### Check datatypes to verify they're correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bdd62961-b9d3-4f0f-9fb0-a19de4bd2000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No           int64\n",
       "year         int64\n",
       "month        int64\n",
       "day          int64\n",
       "hour         int64\n",
       "PM2.5      float64\n",
       "PM10       float64\n",
       "SO2        float64\n",
       "NO2        float64\n",
       "CO         float64\n",
       "O3         float64\n",
       "TEMP       float64\n",
       "PRES       float64\n",
       "DEWP       float64\n",
       "RAIN       float64\n",
       "wd          object\n",
       "WSPM       float64\n",
       "station     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd113d6-ba47-4784-945f-8e98eb3264ca",
   "metadata": {},
   "source": [
    "### Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "84e7055f-5eb4-435e-a34d-d6ec0ff0595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No            0\n",
       "year          0\n",
       "month         0\n",
       "day           0\n",
       "hour          0\n",
       "PM2.5       925\n",
       "PM10        718\n",
       "SO2         935\n",
       "NO2        1023\n",
       "CO         1776\n",
       "O3         1719\n",
       "TEMP         20\n",
       "PRES         20\n",
       "DEWP         20\n",
       "RAIN         20\n",
       "wd           81\n",
       "WSPM         14\n",
       "station       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0693ef-32fb-4102-a72a-260512ad50a1",
   "metadata": {},
   "source": [
    "### Dropped station, not needed for analysis\n",
    "### Dropped rows with null values since dataset is large enough to offset these few observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "450578e3-42d2-4212-bc40-a9684d42421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('station', axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c89877a2-5a69-463a-a638-0657916cb84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  TEMP  \\\n",
       "0   1  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0  -0.7   \n",
       "1   2  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0  -1.1   \n",
       "2   3  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0  -1.1   \n",
       "3   4  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0  -1.4   \n",
       "4   5  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0  -2.0   \n",
       "\n",
       "     PRES  DEWP  RAIN   wd  WSPM  \n",
       "0  1023.0 -18.8   0.0  NNW   4.4  \n",
       "1  1023.2 -18.2   0.0    N   4.7  \n",
       "2  1023.5 -18.2   0.0  NNW   5.6  \n",
       "3  1024.5 -19.4   0.0   NW   3.1  \n",
       "4  1025.2 -19.5   0.0    N   2.0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305c525-850d-4d77-914b-51f369f60cd3",
   "metadata": {},
   "source": [
    "Index built into the dataset is not necessary for classification. Dropped column and reset index. \n",
    "Feature engineering application to date columns. \n",
    "Also, dropped date-related columns to remove redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5d26a31a-5ba1-40e6-9ed5-1168df197b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['No'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c8763b2e-1c7c-4fa5-8e73-ccd3f152bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  TEMP    PRES  \\\n",
       "0  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0  -0.7  1023.0   \n",
       "1  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0  -1.1  1023.2   \n",
       "2  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0  -1.1  1023.5   \n",
       "3  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0  -1.4  1024.5   \n",
       "4  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0  -2.0  1025.2   \n",
       "\n",
       "   DEWP  RAIN   wd  WSPM  \n",
       "0 -18.8   0.0  NNW   4.4  \n",
       "1 -18.2   0.0    N   4.7  \n",
       "2 -18.2   0.0  NNW   5.6  \n",
       "3 -19.4   0.0   NW   3.1  \n",
       "4 -19.5   0.0    N   2.0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a4d39759-13b6-472a-b024-017e265bbb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year       int64\n",
       "month      int64\n",
       "day        int64\n",
       "hour       int64\n",
       "PM2.5    float64\n",
       "PM10     float64\n",
       "SO2      float64\n",
       "NO2      float64\n",
       "CO       float64\n",
       "O3       float64\n",
       "TEMP     float64\n",
       "PRES     float64\n",
       "DEWP     float64\n",
       "RAIN     float64\n",
       "wd        object\n",
       "WSPM     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa611a1-a11e-414d-a0bb-a171ac7c6d20",
   "metadata": {},
   "source": [
    "### Converted categorical variables to numerical variables for corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8ad86ad-f3de-46ad-a6b4-216b54dc0606",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85625e9d-3ba7-4772-890d-ac760dc7e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_encoded = encoder.fit_transform(df[['wd']])  # Encode the 'wd' column\n",
    "wd_labels = encoder.get_feature_names_out(['wd'])  # Get transformed column names\n",
    "\n",
    "df_encoded = pd.DataFrame(wd_encoded, columns=wd_labels)  # Convert to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf9ea65d-8c4e-4ec7-824f-998199665a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['wd'])  # Drop original categorical column\n",
    "df = pd.concat([df, df_encoded], axis=1)  # Merge encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a41adfd7-3900-4589-9292-ca21fee6d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>...</th>\n",
       "      <th>wd_NNW</th>\n",
       "      <th>wd_NW</th>\n",
       "      <th>wd_S</th>\n",
       "      <th>wd_SE</th>\n",
       "      <th>wd_SSE</th>\n",
       "      <th>wd_SSW</th>\n",
       "      <th>wd_SW</th>\n",
       "      <th>wd_W</th>\n",
       "      <th>wd_WNW</th>\n",
       "      <th>wd_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  ...  wd_NNW  \\\n",
       "0  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0  ...     1.0   \n",
       "1  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0  ...     0.0   \n",
       "2  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0  ...     1.0   \n",
       "3  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0  ...     0.0   \n",
       "4  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0  ...     0.0   \n",
       "\n",
       "   wd_NW  wd_S  wd_SE  wd_SSE  wd_SSW  wd_SW  wd_W  wd_WNW  wd_WSW  \n",
       "0    0.0   0.0    0.0     0.0     0.0    0.0   0.0     0.0     0.0  \n",
       "1    0.0   0.0    0.0     0.0     0.0    0.0   0.0     0.0     0.0  \n",
       "2    0.0   0.0    0.0     0.0     0.0    0.0   0.0     0.0     0.0  \n",
       "3    1.0   0.0    0.0     0.0     0.0    0.0   0.0     0.0     0.0  \n",
       "4    0.0   0.0    0.0     0.0     0.0    0.0   0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9510d-7de4-4b92-a3d9-1391a2275802",
   "metadata": {},
   "source": [
    "### Below, we can observe features with high correlation to PM2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59c72e1-2cd0-4abb-80e2-93a5b3d3e1a0",
   "metadata": {},
   "source": [
    "### When testing a df copy for correlation, WSPM seems to be the highest correlation with WD. \n",
    "WSPM also has a really high negative correlation with NO2 so there may be an indirect relationship between the 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f445d2d-8ec0-4570-b741-a6ce59a7ee08",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d1e41d6-a5a4-4442-bb9b-924befbfc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=wd_labels)  # Features\n",
    "y = df[wd_labels]  # One-hot encoded labels\n",
    "\n",
    "#Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f46af327-eca7-4f6d-9d59-17abecd00fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.sum(axis=1).unique())  # Should always be exactly `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2330d78-87c7-4eda-bc49-dfdc1abc8770",
   "metadata": {},
   "source": [
    "# Normalize Data\n",
    "This is done after the split to prevent data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ea54fa3-7cb7-4e40-b94e-312be7702a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d51962c-b755-4685-ba10-b3cf646cc223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0, Max: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(f'Min: {X_train.min()}, Max: {X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c759d-1208-4695-95dd-db951881bdc7",
   "metadata": {},
   "source": [
    "The above pulls minimum and maximum values that help us ensure that values scale down correctly to between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6a270cac-e25d-4cda-af6d-da4ea2b7a7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25452, 15)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5111aa7-bcb0-454f-80a0-346d2b4ae60b",
   "metadata": {},
   "source": [
    "Checked input value for first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "09fd64ca-4d5c-4175-bd2b-b94c04d22f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25452, 16)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37a8ef-656e-4e5b-b500-77ddaffb419f",
   "metadata": {},
   "source": [
    "Checked label count to verify loss. Since we're over 10, we use categorical_crossentropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc51d16-e928-4d17-ba75-5316dbf3cfc9",
   "metadata": {},
   "source": [
    "As shown above, after encoding, we are returning some label values with 0's which is completely destroying the model.\n",
    "*Note:* This is no longer displayed above, as the results no longer err after resolving the issue. It seems get_dummies() was removing 1 of 16 labels. Switching to OneHotEncoder resolved this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2883116-b7c7-480b-944f-02cd5c68f162",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba2157fa-3b2b-48a4-98b4-f115c1d3d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = keras.Sequential()\n",
    "tf_model.add(layers.Dense(15, activation='relu')) # per feedback from last weeks assignment, first layer begins with the same neurons as features\n",
    "tf_model.add(layers.Dense(20, activation='relu')) # first hidden layer with 20 neurons, per requirements of the assignment\n",
    "tf_model.add(layers.Dense(10, activation='relu')) # second hidden layer with 10 neurons, as above\n",
    "tf_model.add(layers.Dense(16, activation='softmax')) # final layer to match the number of labels for prediction\n",
    "\n",
    "tf_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c3f0a09-bb58-4c19-9fef-a0266cb5d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.6168 - accuracy: 0.1630 - val_loss: 2.5056 - val_accuracy: 0.1993\n",
      "Epoch 2/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.4694 - accuracy: 0.1967 - val_loss: 2.4236 - val_accuracy: 0.2070\n",
      "Epoch 3/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.4114 - accuracy: 0.2047 - val_loss: 2.3862 - val_accuracy: 0.2098\n",
      "Epoch 4/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.3831 - accuracy: 0.2106 - val_loss: 2.3657 - val_accuracy: 0.2150\n",
      "Epoch 5/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3657 - accuracy: 0.2159 - val_loss: 2.3571 - val_accuracy: 0.2169\n",
      "Epoch 6/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3529 - accuracy: 0.2194 - val_loss: 2.3419 - val_accuracy: 0.2232\n",
      "Epoch 7/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3433 - accuracy: 0.2209 - val_loss: 2.3328 - val_accuracy: 0.2229\n",
      "Epoch 8/100\n",
      "796/796 [==============================] - 17s 21ms/step - loss: 2.3344 - accuracy: 0.2206 - val_loss: 2.3290 - val_accuracy: 0.2279\n",
      "Epoch 9/100\n",
      "796/796 [==============================] - 4s 5ms/step - loss: 2.3290 - accuracy: 0.2262 - val_loss: 2.3257 - val_accuracy: 0.2280\n",
      "Epoch 10/100\n",
      "796/796 [==============================] - 36s 46ms/step - loss: 2.3224 - accuracy: 0.2285 - val_loss: 2.3163 - val_accuracy: 0.2274\n",
      "Epoch 11/100\n",
      "796/796 [==============================] - 37s 46ms/step - loss: 2.3160 - accuracy: 0.2287 - val_loss: 2.3156 - val_accuracy: 0.2307\n",
      "Epoch 12/100\n",
      "796/796 [==============================] - 28s 35ms/step - loss: 2.3107 - accuracy: 0.2298 - val_loss: 2.3075 - val_accuracy: 0.2321\n",
      "Epoch 13/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3054 - accuracy: 0.2331 - val_loss: 2.3022 - val_accuracy: 0.2337\n",
      "Epoch 14/100\n",
      "796/796 [==============================] - 3s 3ms/step - loss: 2.3023 - accuracy: 0.2329 - val_loss: 2.2978 - val_accuracy: 0.2315\n",
      "Epoch 15/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2983 - accuracy: 0.2356 - val_loss: 2.2961 - val_accuracy: 0.2357\n",
      "Epoch 16/100\n",
      "796/796 [==============================] - 36s 46ms/step - loss: 2.2941 - accuracy: 0.2353 - val_loss: 2.2897 - val_accuracy: 0.2405\n",
      "Epoch 17/100\n",
      "796/796 [==============================] - 36s 46ms/step - loss: 2.2919 - accuracy: 0.2365 - val_loss: 2.2879 - val_accuracy: 0.2389\n",
      "Epoch 18/100\n",
      "796/796 [==============================] - 14s 17ms/step - loss: 2.2882 - accuracy: 0.2387 - val_loss: 2.2830 - val_accuracy: 0.2386\n",
      "Epoch 19/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.2843 - accuracy: 0.2381 - val_loss: 2.2841 - val_accuracy: 0.2378\n",
      "Epoch 20/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2831 - accuracy: 0.2380 - val_loss: 2.2806 - val_accuracy: 0.2405\n",
      "Epoch 21/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2801 - accuracy: 0.2396 - val_loss: 2.2757 - val_accuracy: 0.2425\n",
      "Epoch 22/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2768 - accuracy: 0.2406 - val_loss: 2.2818 - val_accuracy: 0.2389\n",
      "Epoch 23/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2749 - accuracy: 0.2408 - val_loss: 2.2717 - val_accuracy: 0.2456\n",
      "Epoch 24/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2722 - accuracy: 0.2425 - val_loss: 2.2774 - val_accuracy: 0.2427\n",
      "Epoch 25/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2694 - accuracy: 0.2431 - val_loss: 2.2736 - val_accuracy: 0.2427\n",
      "Epoch 26/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2681 - accuracy: 0.2421 - val_loss: 2.2692 - val_accuracy: 0.2439\n",
      "Epoch 27/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2661 - accuracy: 0.2451 - val_loss: 2.2687 - val_accuracy: 0.2423\n",
      "Epoch 28/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2639 - accuracy: 0.2447 - val_loss: 2.2748 - val_accuracy: 0.2431\n",
      "Epoch 29/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2620 - accuracy: 0.2438 - val_loss: 2.2649 - val_accuracy: 0.2423\n",
      "Epoch 30/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2593 - accuracy: 0.2461 - val_loss: 2.2693 - val_accuracy: 0.2398\n",
      "Epoch 31/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2572 - accuracy: 0.2456 - val_loss: 2.2659 - val_accuracy: 0.2414\n",
      "Epoch 32/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2555 - accuracy: 0.2479 - val_loss: 2.2613 - val_accuracy: 0.2428\n",
      "Epoch 33/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2523 - accuracy: 0.2484 - val_loss: 2.2572 - val_accuracy: 0.2464\n",
      "Epoch 34/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2499 - accuracy: 0.2468 - val_loss: 2.2638 - val_accuracy: 0.2370\n",
      "Epoch 35/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2491 - accuracy: 0.2474 - val_loss: 2.2596 - val_accuracy: 0.2397\n",
      "Epoch 36/100\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.2476 - accuracy: 0.2472 - val_loss: 2.2536 - val_accuracy: 0.2423\n",
      "Epoch 37/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2449 - accuracy: 0.2495 - val_loss: 2.2605 - val_accuracy: 0.2372\n",
      "Epoch 38/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2433 - accuracy: 0.2476 - val_loss: 2.2580 - val_accuracy: 0.2408\n",
      "Epoch 39/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2409 - accuracy: 0.2513 - val_loss: 2.2542 - val_accuracy: 0.2376\n",
      "Epoch 40/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2407 - accuracy: 0.2496 - val_loss: 2.2485 - val_accuracy: 0.2403\n",
      "Epoch 41/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2387 - accuracy: 0.2508 - val_loss: 2.2481 - val_accuracy: 0.2390\n",
      "Epoch 42/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2374 - accuracy: 0.2508 - val_loss: 2.2481 - val_accuracy: 0.2450\n",
      "Epoch 43/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2361 - accuracy: 0.2500 - val_loss: 2.2517 - val_accuracy: 0.2431\n",
      "Epoch 44/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2345 - accuracy: 0.2513 - val_loss: 2.2490 - val_accuracy: 0.2401\n",
      "Epoch 45/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2328 - accuracy: 0.2489 - val_loss: 2.2464 - val_accuracy: 0.2428\n",
      "Epoch 46/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2321 - accuracy: 0.2505 - val_loss: 2.2498 - val_accuracy: 0.2438\n",
      "Epoch 47/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2300 - accuracy: 0.2513 - val_loss: 2.2436 - val_accuracy: 0.2428\n",
      "Epoch 48/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2291 - accuracy: 0.2521 - val_loss: 2.2415 - val_accuracy: 0.2431\n",
      "Epoch 49/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2289 - accuracy: 0.2514 - val_loss: 2.2546 - val_accuracy: 0.2419\n",
      "Epoch 50/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2263 - accuracy: 0.2516 - val_loss: 2.2576 - val_accuracy: 0.2397\n",
      "Epoch 51/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2262 - accuracy: 0.2520 - val_loss: 2.2477 - val_accuracy: 0.2406\n",
      "Epoch 52/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2246 - accuracy: 0.2508 - val_loss: 2.2362 - val_accuracy: 0.2455\n",
      "Epoch 53/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2245 - accuracy: 0.2528 - val_loss: 2.2463 - val_accuracy: 0.2386\n",
      "Epoch 54/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2234 - accuracy: 0.2506 - val_loss: 2.2380 - val_accuracy: 0.2474\n",
      "Epoch 55/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2224 - accuracy: 0.2531 - val_loss: 2.2425 - val_accuracy: 0.2420\n",
      "Epoch 56/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2212 - accuracy: 0.2532 - val_loss: 2.2418 - val_accuracy: 0.2427\n",
      "Epoch 57/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2205 - accuracy: 0.2539 - val_loss: 2.2397 - val_accuracy: 0.2431\n",
      "Epoch 58/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2194 - accuracy: 0.2524 - val_loss: 2.2393 - val_accuracy: 0.2450\n",
      "Epoch 59/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2176 - accuracy: 0.2523 - val_loss: 2.2361 - val_accuracy: 0.2431\n",
      "Epoch 60/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2166 - accuracy: 0.2542 - val_loss: 2.2374 - val_accuracy: 0.2408\n",
      "Epoch 61/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2171 - accuracy: 0.2533 - val_loss: 2.2327 - val_accuracy: 0.2469\n",
      "Epoch 62/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2160 - accuracy: 0.2514 - val_loss: 2.2411 - val_accuracy: 0.2447\n",
      "Epoch 63/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2151 - accuracy: 0.2531 - val_loss: 2.2406 - val_accuracy: 0.2422\n",
      "Epoch 64/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2134 - accuracy: 0.2557 - val_loss: 2.2419 - val_accuracy: 0.2417\n",
      "Epoch 65/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2147 - accuracy: 0.2541 - val_loss: 2.2325 - val_accuracy: 0.2411\n",
      "Epoch 66/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2126 - accuracy: 0.2552 - val_loss: 2.2313 - val_accuracy: 0.2441\n",
      "Epoch 67/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2124 - accuracy: 0.2531 - val_loss: 2.2354 - val_accuracy: 0.2427\n",
      "Epoch 68/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2123 - accuracy: 0.2539 - val_loss: 2.2290 - val_accuracy: 0.2461\n",
      "Epoch 69/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2112 - accuracy: 0.2554 - val_loss: 2.2266 - val_accuracy: 0.2456\n",
      "Epoch 70/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2102 - accuracy: 0.2550 - val_loss: 2.2474 - val_accuracy: 0.2428\n",
      "Epoch 71/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2105 - accuracy: 0.2557 - val_loss: 2.2327 - val_accuracy: 0.2466\n",
      "Epoch 72/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2092 - accuracy: 0.2540 - val_loss: 2.2313 - val_accuracy: 0.2441\n",
      "Epoch 73/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2084 - accuracy: 0.2532 - val_loss: 2.2297 - val_accuracy: 0.2466\n",
      "Epoch 74/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2088 - accuracy: 0.2555 - val_loss: 2.2358 - val_accuracy: 0.2445\n",
      "Epoch 75/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2071 - accuracy: 0.2562 - val_loss: 2.2297 - val_accuracy: 0.2445\n",
      "Epoch 76/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2077 - accuracy: 0.2546 - val_loss: 2.2303 - val_accuracy: 0.2456\n",
      "Epoch 77/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2066 - accuracy: 0.2554 - val_loss: 2.2325 - val_accuracy: 0.2447\n",
      "Epoch 78/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2063 - accuracy: 0.2556 - val_loss: 2.2278 - val_accuracy: 0.2474\n",
      "Epoch 79/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2071 - accuracy: 0.2562 - val_loss: 2.2310 - val_accuracy: 0.2464\n",
      "Epoch 80/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2062 - accuracy: 0.2548 - val_loss: 2.2330 - val_accuracy: 0.2394\n",
      "Epoch 81/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2045 - accuracy: 0.2557 - val_loss: 2.2270 - val_accuracy: 0.2436\n",
      "Epoch 82/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2055 - accuracy: 0.2558 - val_loss: 2.2279 - val_accuracy: 0.2478\n",
      "Epoch 83/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2047 - accuracy: 0.2548 - val_loss: 2.2344 - val_accuracy: 0.2442\n",
      "Epoch 84/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2055 - accuracy: 0.2568 - val_loss: 2.2254 - val_accuracy: 0.2449\n",
      "Epoch 85/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2028 - accuracy: 0.2548 - val_loss: 2.2364 - val_accuracy: 0.2478\n",
      "Epoch 86/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2034 - accuracy: 0.2544 - val_loss: 2.2351 - val_accuracy: 0.2449\n",
      "Epoch 87/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2021 - accuracy: 0.2538 - val_loss: 2.2279 - val_accuracy: 0.2467\n",
      "Epoch 88/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2031 - accuracy: 0.2533 - val_loss: 2.2244 - val_accuracy: 0.2489\n",
      "Epoch 89/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2035 - accuracy: 0.2553 - val_loss: 2.2250 - val_accuracy: 0.2449\n",
      "Epoch 90/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2028 - accuracy: 0.2573 - val_loss: 2.2219 - val_accuracy: 0.2461\n",
      "Epoch 91/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2019 - accuracy: 0.2563 - val_loss: 2.2253 - val_accuracy: 0.2469\n",
      "Epoch 92/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2011 - accuracy: 0.2568 - val_loss: 2.2297 - val_accuracy: 0.2478\n",
      "Epoch 93/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2016 - accuracy: 0.2563 - val_loss: 2.2285 - val_accuracy: 0.2472\n",
      "Epoch 94/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1997 - accuracy: 0.2556 - val_loss: 2.2308 - val_accuracy: 0.2464\n",
      "Epoch 95/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2012 - accuracy: 0.2561 - val_loss: 2.2266 - val_accuracy: 0.2493\n",
      "Epoch 96/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2010 - accuracy: 0.2572 - val_loss: 2.2296 - val_accuracy: 0.2458\n",
      "Epoch 97/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1989 - accuracy: 0.2548 - val_loss: 2.2273 - val_accuracy: 0.2482\n",
      "Epoch 98/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1997 - accuracy: 0.2549 - val_loss: 2.2215 - val_accuracy: 0.2488\n",
      "Epoch 99/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1995 - accuracy: 0.2570 - val_loss: 2.2278 - val_accuracy: 0.2469\n",
      "Epoch 100/100\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1989 - accuracy: 0.2565 - val_loss: 2.2258 - val_accuracy: 0.2455\n",
      "CPU times: total: 7min 50s\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set random seed \n",
    "tf.random.set_seed(1)\n",
    "# Fit the model and save the results in history\n",
    "history = tf_model.fit(x=X_train, y=y_train, batch_size=32, epochs=100,\n",
    "          validation_data=(X_test,y_test), verbose= 1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd9bad91-8e5c-440b-bd00-6f5807993d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.201011</td>\n",
       "      <td>0.257190</td>\n",
       "      <td>2.229564</td>\n",
       "      <td>0.245796</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.198872</td>\n",
       "      <td>0.254833</td>\n",
       "      <td>2.227260</td>\n",
       "      <td>0.248153</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.199653</td>\n",
       "      <td>0.254911</td>\n",
       "      <td>2.221512</td>\n",
       "      <td>0.248782</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.199484</td>\n",
       "      <td>0.256954</td>\n",
       "      <td>2.227775</td>\n",
       "      <td>0.246896</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.198917</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>2.225793</td>\n",
       "      <td>0.245482</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy  epoch\n",
       "95  2.201011  0.257190  2.229564      0.245796     95\n",
       "96  2.198872  0.254833  2.227260      0.248153     96\n",
       "97  2.199653  0.254911  2.221512      0.248782     97\n",
       "98  2.199484  0.256954  2.227775      0.246896     98\n",
       "99  2.198917  0.256522  2.225793      0.245482     99"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to df for performance visualization\n",
    "trainhist = pd.DataFrame(history.history)\n",
    "# add epoch column for x value in visualization/progression\n",
    "trainhist['epoch'] = history.epoch\n",
    "# results\n",
    "trainhist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1676169f-2580-4633-bf09-ffc8794ea027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23ecbf4b220>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loss\n",
    "sns.lineplot(x='epoch', y='loss', data=trainhist)\n",
    "# Validation loss\n",
    "sns.lineplot(x='epoch', y='val_loss', data=trainhist)\n",
    "# Legend\n",
    "plt.legend(labels=['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe34d5b-d8fb-4f95-8cf8-b52f0e9104c3",
   "metadata": {},
   "source": [
    "The model above definitely overfits the data. We can see that by the continued improvement on training data with a plateau in validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37a4bddc-2cb4-4761-9b8b-1897db3ee23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1] #input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "635a29bf-559c-410b-a8a6-7c8d369ba40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1] #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60eb74f4-90a1-434d-9cd9-1782105bb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d15f6f8b-e4b4-4d9b-adce-0834d5cc8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    hp_units1 = hp.Int('unit1', min_value=20, max_value=100, step=5)\n",
    "    hp_units2 = hp.Int('unit2', min_value=10, max_value=50, step=2)\n",
    "    hp_dropout1 = hp.Float('rate1', min_value = 0.2, max_value=0.8, step=0.1)\n",
    "    hp_dropout2 = hp.Float('rate1', min_value = 0.2, max_value=0.8, step=0.1)\n",
    "\n",
    "    model.add(layers.Dense(units=15, activation='relu')) # Input Layer\n",
    "\n",
    "    model.add(layers.Dense(units = hp_units1, activation='relu')) # Hidden layer 1\n",
    "    model.add(Dropout(rate=hp_dropout1))\n",
    "\n",
    "    model.add(layers.Dense(units = hp_units2, activation='relu')) # Hidden layer 2\n",
    "    model.add(Dropout(rate=hp_dropout2))\n",
    "\n",
    "    model.add(layers.Dense(units=16, activation='softmax')) # Output Layer\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a13216e1-2d87-400f-8adc-402107a46c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from Project3\\wd_pred\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder, #Specify the model\n",
    "                     objective = 'val_loss', #Specify the objective funciton\n",
    "                     max_epochs = 100, #Specify the maximum epochs\n",
    "                     directory = 'Project3', #Specify the file path\n",
    "                     project_name = 'wd_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a257939-d11f-4aeb-8ee3-5661d79d74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "556a71e6-85bd-4858-bd2f-c11d4962587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 01m 13s]\n",
      "val_loss: 2.275911808013916\n",
      "\n",
      "Best val_loss So Far: 2.1935341358184814\n",
      "Total elapsed time: 01h 11m 55s\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('Project3')\n",
    "# Perform search\n",
    "tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53e2e7d6-3116-44d2-aad9-0ca144a39fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found: {'units': 10, 'rate': 0.4, 'learning_rate': 0.0001, 'unit1': 90, 'unit2': 50, 'rate1': 0.2, 'tuner/epochs': 100, 'tuner/initial_epoch': 34, 'tuner/bracket': 4, 'tuner/round': 4, 'tuner/trial_id': '0142'}\n",
      "\n",
      "The optimal number of units in the input layer:             10        \n",
      "The optimal number of units in the first hidden layer:      90        \n",
      "The optimal dropout rate in the first hidden layer:         0.2       \n",
      "The optimal number of units in the second hidden layer:     50        \n",
      "The optimal dropout rate in the second hidden layer:        0.2       \n",
      "The optimal learning rate for the optimizer of Adam:        0.0001    \n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best hyperparameters found: {best_hps.values}\")\n",
    "\n",
    "print()\n",
    "print(f\"{'The optimal number of units in the input layer:':<60}{best_hps.get('units'):<10}\") \n",
    "print(f\"{'The optimal number of units in the first hidden layer:':<60}{best_hps.get('unit1'):<10}\") \n",
    "print(f\"{'The optimal dropout rate in the first hidden layer:':<60}{best_hps.get('rate1'):<10}\")\n",
    "print(f\"{'The optimal number of units in the second hidden layer:':<60}{best_hps.get('unit2'):<10}\")\n",
    "print(f\"{'The optimal dropout rate in the second hidden layer:':<60}{best_hps.get('rate1'):<10}\")\n",
    "print(f\"{'The optimal learning rate for the optimizer of Adam:':<60}{best_hps.get('learning_rate'):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2832816-1a18-4ef5-908b-24c1fc639897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "796/796 [==============================] - 3s 3ms/step - loss: 2.5468 - accuracy: 0.1794 - val_loss: 2.4147 - val_accuracy: 0.2107\n",
      "Epoch 2/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.4168 - accuracy: 0.2061 - val_loss: 2.3624 - val_accuracy: 0.2200\n",
      "Epoch 3/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.3754 - accuracy: 0.2168 - val_loss: 2.3360 - val_accuracy: 0.2243\n",
      "Epoch 4/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.3542 - accuracy: 0.2199 - val_loss: 2.3207 - val_accuracy: 0.2271\n",
      "Epoch 5/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.3439 - accuracy: 0.2251 - val_loss: 2.3171 - val_accuracy: 0.2309\n",
      "Epoch 6/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.3276 - accuracy: 0.2274 - val_loss: 2.3016 - val_accuracy: 0.2280\n",
      "Epoch 7/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3197 - accuracy: 0.2309 - val_loss: 2.2899 - val_accuracy: 0.2359\n",
      "Epoch 8/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3111 - accuracy: 0.2312 - val_loss: 2.2923 - val_accuracy: 0.2409\n",
      "Epoch 9/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.3053 - accuracy: 0.2354 - val_loss: 2.2773 - val_accuracy: 0.2417\n",
      "Epoch 10/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2994 - accuracy: 0.2381 - val_loss: 2.2708 - val_accuracy: 0.2365\n",
      "Epoch 11/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.2903 - accuracy: 0.2362 - val_loss: 2.2696 - val_accuracy: 0.2400\n",
      "Epoch 12/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2819 - accuracy: 0.2393 - val_loss: 2.2642 - val_accuracy: 0.2409\n",
      "Epoch 13/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.2751 - accuracy: 0.2433 - val_loss: 2.2584 - val_accuracy: 0.2416\n",
      "Epoch 14/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2698 - accuracy: 0.2404 - val_loss: 2.2534 - val_accuracy: 0.2436\n",
      "Epoch 15/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2698 - accuracy: 0.2416 - val_loss: 2.2526 - val_accuracy: 0.2456\n",
      "Epoch 16/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2639 - accuracy: 0.2429 - val_loss: 2.2450 - val_accuracy: 0.2430\n",
      "Epoch 17/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.2589 - accuracy: 0.2449 - val_loss: 2.2362 - val_accuracy: 0.2486\n",
      "Epoch 18/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2562 - accuracy: 0.2488 - val_loss: 2.2352 - val_accuracy: 0.2467\n",
      "Epoch 19/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2509 - accuracy: 0.2445 - val_loss: 2.2375 - val_accuracy: 0.2474\n",
      "Epoch 20/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2466 - accuracy: 0.2483 - val_loss: 2.2303 - val_accuracy: 0.2477\n",
      "Epoch 21/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2446 - accuracy: 0.2516 - val_loss: 2.2242 - val_accuracy: 0.2464\n",
      "Epoch 22/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2410 - accuracy: 0.2478 - val_loss: 2.2309 - val_accuracy: 0.2445\n",
      "Epoch 23/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2372 - accuracy: 0.2515 - val_loss: 2.2229 - val_accuracy: 0.2519\n",
      "Epoch 24/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2340 - accuracy: 0.2483 - val_loss: 2.2208 - val_accuracy: 0.2510\n",
      "Epoch 25/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2331 - accuracy: 0.2533 - val_loss: 2.2130 - val_accuracy: 0.2510\n",
      "Epoch 26/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2275 - accuracy: 0.2511 - val_loss: 2.2149 - val_accuracy: 0.2527\n",
      "Epoch 27/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2247 - accuracy: 0.2528 - val_loss: 2.2153 - val_accuracy: 0.2488\n",
      "Epoch 28/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2243 - accuracy: 0.2512 - val_loss: 2.2127 - val_accuracy: 0.2519\n",
      "Epoch 29/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2183 - accuracy: 0.2536 - val_loss: 2.2034 - val_accuracy: 0.2505\n",
      "Epoch 30/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2149 - accuracy: 0.2549 - val_loss: 2.2084 - val_accuracy: 0.2511\n",
      "Epoch 31/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2144 - accuracy: 0.2529 - val_loss: 2.2161 - val_accuracy: 0.2524\n",
      "Epoch 32/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2114 - accuracy: 0.2574 - val_loss: 2.2009 - val_accuracy: 0.2538\n",
      "Epoch 33/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2089 - accuracy: 0.2554 - val_loss: 2.2016 - val_accuracy: 0.2563\n",
      "Epoch 34/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2029 - accuracy: 0.2578 - val_loss: 2.1970 - val_accuracy: 0.2579\n",
      "Epoch 35/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2105 - accuracy: 0.2541 - val_loss: 2.2007 - val_accuracy: 0.2576\n",
      "Epoch 36/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2030 - accuracy: 0.2550 - val_loss: 2.1967 - val_accuracy: 0.2576\n",
      "Epoch 37/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.2006 - accuracy: 0.2586 - val_loss: 2.2012 - val_accuracy: 0.2565\n",
      "Epoch 38/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1980 - accuracy: 0.2595 - val_loss: 2.1995 - val_accuracy: 0.2548\n",
      "Epoch 39/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1955 - accuracy: 0.2621 - val_loss: 2.1933 - val_accuracy: 0.2537\n",
      "Epoch 40/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1952 - accuracy: 0.2613 - val_loss: 2.1920 - val_accuracy: 0.2527\n",
      "Epoch 41/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.1915 - accuracy: 0.2595 - val_loss: 2.1905 - val_accuracy: 0.2571\n",
      "Epoch 42/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1911 - accuracy: 0.2599 - val_loss: 2.1939 - val_accuracy: 0.2541\n",
      "Epoch 43/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1873 - accuracy: 0.2592 - val_loss: 2.1914 - val_accuracy: 0.2562\n",
      "Epoch 44/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1905 - accuracy: 0.2613 - val_loss: 2.1907 - val_accuracy: 0.2576\n",
      "Epoch 45/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1862 - accuracy: 0.2584 - val_loss: 2.1864 - val_accuracy: 0.2522\n",
      "Epoch 46/50\n",
      "796/796 [==============================] - 2s 2ms/step - loss: 2.1849 - accuracy: 0.2611 - val_loss: 2.1848 - val_accuracy: 0.2573\n",
      "Epoch 47/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1803 - accuracy: 0.2634 - val_loss: 2.1836 - val_accuracy: 0.2563\n",
      "Epoch 48/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1830 - accuracy: 0.2614 - val_loss: 2.1842 - val_accuracy: 0.2530\n",
      "Epoch 49/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1815 - accuracy: 0.2587 - val_loss: 2.1791 - val_accuracy: 0.2573\n",
      "Epoch 50/50\n",
      "796/796 [==============================] - 2s 3ms/step - loss: 2.1819 - accuracy: 0.2649 - val_loss: 2.1923 - val_accuracy: 0.2554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2406b693130>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e8e9d-d4e3-4469-8aa1-d835c05e5aa0",
   "metadata": {},
   "source": [
    "The above reflects a val_loss decrease from 2.2258 to 2.1923 and accuracy from 24.55% to 25.55%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6dc992-24f6-4c04-a869-b7a525004550",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f34369-ad9b-40c6-88c6-a8e4a4abc0a4",
   "metadata": {},
   "source": [
    "New Train Test Split to fit PyTorch single y-value requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ed85df4-1aba-408d-b093-eef4edab9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('wd', axis=1)  # Features\n",
    "y = df['wd']\n",
    "\n",
    "#Split the data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a07886-0054-472e-a39a-84e5e550369a",
   "metadata": {},
   "source": [
    "### Encode labels and convert arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "de8d9854-8f3e-4970-bc71-0f891703309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values.astype(np.float32))\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # Converts labels to integers\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_train = torch.tensor(y_train.astype(np.int64)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0000e747-c6a7-4c8f-bed4-f0a5aa9b91f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25452, 15])\n",
      "torch.Size([25452, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)  # Features\n",
    "print(y_train.shape)  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6097adac-dd98-431b-8ebe-9baf78496ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6363, 15])\n",
      "torch.Size([6363, 1])\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.tensor(X_test.values.astype(np.float32))\n",
    "y_test = torch.tensor(y_test.astype(np.int64)).reshape(-1, 1)\n",
    "\n",
    "print(X_test.shape)  # Features in the test set\n",
    "print(y_test.shape)  # Labels in the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe7a54-d7cc-44d8-bf89-4a5482ca58ff",
   "metadata": {},
   "source": [
    "Verified that all tensors line up correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1104fa3b-850b-4580-bee0-5c3ca31618a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "54eaf581-f273-4855-b586-6a36162b02cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "dd1de39a-0b6f-4113-abd4-ccff39952488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "output_size = len(y_train.unique())\n",
    "hidden_size = [20, 10]\n",
    "\n",
    "print(input_size)\n",
    "print(output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6ca62-64d4-4e9a-a449-3b765dee420e",
   "metadata": {},
   "source": [
    "# Define the Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cb0fc378-9bee-43d1-9deb-47c00b246151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassificationModel(torch.nn.Module):\n",
    "    # constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LinearClassificationModel, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(input_size, hidden_size[0])\n",
    "        self.hidden2 = torch.nn.Linear(hidden_size[0], hidden_size[1])\n",
    "        self.predict = torch.nn.Linear(hidden_size[1], output_size)\n",
    "    # forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        y_pred = F.log_softmax(self.predict(x), dim=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5a2c46d4-7aa2-4fff-9c4c-d4d60fc7c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = LinearClassificationModel(input_size, hidden_size, output_size)\n",
    "l = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(pt_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fdaac5ed-66f6-425f-bac8-bb34d115821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.squeeze()  # Removes the extra dimension\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e3978bb1-3874-491a-90d2-d0e3b432c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss = 55.2769 and val_loss = 605.5320\n",
      "epoch 100, loss = 2.8024 and val_loss = 2.8040\n",
      "epoch 200, loss = 2.7847 and val_loss = 2.7857\n",
      "epoch 300, loss = 2.7692 and val_loss = 2.7695\n",
      "epoch 400, loss = 2.7556 and val_loss = 2.7554\n",
      "CPU times: total: 21.6 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set random seeds\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# set epochs\n",
    "\n",
    "num_epochs=500\n",
    "\n",
    "train_loss = [None]*num_epochs\n",
    "validation_loss = [None]*num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    output = pt_model(X_train)\n",
    "    loss = l(output, y_train)\n",
    "    train_loss[epoch] = loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Stop tracking gradient\n",
    "    y_pred = pt_model(X_test).detach()\n",
    "    val_loss = l(y_pred, y_test)\n",
    "    validation_loss[epoch] = val_loss.item()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch {epoch}, loss = {loss.item():.4f} and val_loss = {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6099a9b0-9ac4-41ab-a607-e1a458e23c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2.744361</td>\n",
       "      <td>2.743567</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2.744250</td>\n",
       "      <td>2.743451</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2.744139</td>\n",
       "      <td>2.743335</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2.744029</td>\n",
       "      <td>2.743219</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2.743918</td>\n",
       "      <td>2.743104</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train_loss  val_loss  epoch\n",
       "495    2.744361  2.743567    495\n",
       "496    2.744250  2.743451    496\n",
       "497    2.744139  2.743335    497\n",
       "498    2.744029  2.743219    498\n",
       "499    2.743918  2.743104    499"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainhist3 = pd.DataFrame({'train_loss': train_loss, 'val_loss': validation_loss, 'epoch':np.arange(num_epochs)})\n",
    "\n",
    "trainhist3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e181b675-33a9-45cb-8d90-e15228add840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x240adac9c30>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train loss\n",
    "sns.lineplot(x='epoch', y ='train_loss', data =trainhist3)\n",
    "# Validation loss\n",
    "sns.lineplot(x='epoch', y ='val_loss', data =trainhist3)\n",
    "#Add legends\n",
    "plt.legend(labels=['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f56fd-c9c9-4a8f-bc70-9367806567fc",
   "metadata": {},
   "source": [
    "Interestingly, the validation loss appears to shrink more than the training loss. <br /> \n",
    "We have extremely early plateau occurring after a very steep drop. <br />\n",
    "The curve could likely benefit from dropout, but regardless, <br />\n",
    "it converges really well with epoch 500 showing a slightly lower loss than training_loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53e7dc-004e-4497-b956-2b69bfc37d40",
   "metadata": {},
   "source": [
    "### For the above reasons, I would say that this slightly underfits the data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
